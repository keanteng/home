<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Data Cleaning | Kean Teng Blog</title>
<meta name="keywords" content="Pandas, Data Frame, Data Cleaning, Data Manipulation, Python">
<meta name="description" content="My Kaggle Learning Note ">
<meta name="author" content="Kean Teng Blog">
<link rel="canonical" href="https://keanteng.github.io/home/docs/2023-08-19-data-cleaning/">
<link crossorigin="anonymous" href="/home/assets/css/stylesheet.3609ac0fb85d7c541bc02f22afb84e98fecc845be8138dfe1ac5d77feae14cb1.css" integrity="sha256-NgmsD7hdfFQbwC8ir7hOmP7MhFvoE43&#43;GsXXf&#43;rhTLE=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://i.postimg.cc/0Qq5g2fX/favicon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://keanteng.github.io/home/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://keanteng.github.io/home/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://keanteng.github.io/home/apple-touch-icon.png">
<link rel="mask-icon" href="https://keanteng.github.io/home/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Data Cleaning" />
<meta property="og:description" content="My Kaggle Learning Note " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://keanteng.github.io/home/docs/2023-08-19-data-cleaning/" /><meta property="og:image" content="https://keanteng.github.io/home/papermod-cover.png"/><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2023-08-19T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-08-19T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://keanteng.github.io/home/papermod-cover.png"/>

<meta name="twitter:title" content="Data Cleaning"/>
<meta name="twitter:description" content="My Kaggle Learning Note "/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "https://keanteng.github.io/home/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Data Cleaning",
      "item": "https://keanteng.github.io/home/docs/2023-08-19-data-cleaning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Data Cleaning",
  "name": "Data Cleaning",
  "description": "My Kaggle Learning Note ",
  "keywords": [
    "Pandas", "Data Frame", "Data Cleaning", "Data Manipulation", "Python"
  ],
  "articleBody": " Images from Unsplash\nDisclaimer: This article is my learning note from the courses I took from Kaggle.\nData cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. It is a key part of data science, and it can be deeply frustrating. What should we do to the missing values? Why the dates are not in the correct format? How to clean up inconsistent data entry? These are some of the problems that we will learn to tackle in this course.\n1. Handling Missing Values Let’s start by taking a look at the data and check how many missing values are there:\ndf.head() missing = df.isnull().sum() print(missing) Now let’s look at the percentage of values in our dataset that were missing:\ntotal_cells = np.product(df.shape) total_missing = missing.sum() percent_missing = (total_missing/total_cells)*100 print(percent_missing) The next step is to figure out why the data is missing. It is important to ask ourselves, is this value missing because it wasn’t recorded, or it doesn’t exist? If it is the latter, it wouldn’t make sense to guess those values, we could just leave them empty. But if it is the other way round, we probably would need to guess what it might have been based on some other values in the column and row.\nWe called this method as imputation. In statistics, imputation is the process of replacing missing data with substituted values.\n# look at the # of missing points in the first ten columns missing_values_count[0:10] Date 0 GameID 0 Drive 0 qtr 0 down 61154 time 224 TimeUnder 0 TimeSecs 224 PlayTimeDiff 444 SideofField 528 dtype: int64 We can see that the columns has information on the number of seconds left in the game when the play was made. These values are probably missing because they were not recorded, it would be better for us to try and have a guess on it.\nConversely, other fields such as PenalizedTeam contains a lot of missing fields. This is because if there was no penalty, then the field will be missed. We could just leave it empty as it is.\nOf course, if we wouldn’t want to guess for the missing value, we can remove the rows of columns with missing values:\ndf.dropna() # remove rows with missing value df.dropna(axis = 1) # remove all columns with at least one missing value On the other hand, if we would like to try to fill in the missing value, we can use the Pandas’ fillna function:\n# get a small subset of the NFL dataset subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head() subset_nfl_data # replace all NA's with 0 subset_nfl_data.fillna(0) If we want to replace the missing value with value comes directly after it in the same column:\n# replace all NA's the value that comes directly after it in the same column, # then replace all the remaining na's with 0 subset_nfl_data.fillna(method='bfill', axis=0).fillna(0) 2. Scaling \u0026 Normalization Let’s start by importing some libraries:\n# modules we'll use import pandas as pd import numpy as np # for Box-Cox Transformation from scipy import stats # for min_max scaling from mlxtend.preprocessing import minmax_scaling # plotting modules import seaborn as sns import matplotlib.pyplot as plt The difference between scaling and normalization:\nScaling: changing the range of data Normalization: changing the shape of the distribution of the data When we perform scaling, we are transforming the data so that it fits within a specific scale like 0 to 1 or 1 to 100. We will scale data if we are using methods based on measures of how far apart data points are such as SVM (support vector machines) and KNN (k-nearest neighbors).\nFor example, you might be looking at the prices of some products in both Yen and US Dollars. One US Dollar is worth about 100 Yen, but if you don’t scale your prices, methods like SVM or KNN will consider a difference in price of 1 Yen as important as a difference of 1 US Dollar! This clearly doesn’t fit with our intuitions of the world. With currency, you can convert between currencies. But what about if you’re looking at something like height and weight? It’s not entirely clear how many pounds should equal one inch (or how many kilograms should equal one meter).\nScaling variables help us to compare different variables on equal footing. The shape of the data will not change with scaling, but the range will change.\n# generate 1000 data points randomly drawn from an exponential distribution original_data = np.random.exponential(size=1000) # mix-max scale the data between 0 and 1 scaled_data = minmax_scaling(original_data, columns=[0]) # plot both together to compare fig, ax = plt.subplots(1, 2, figsize=(15, 3)) sns.histplot(original_data, ax=ax[0], kde=True, legend=False) ax[0].set_title(\"Original Data\") sns.histplot(scaled_data, ax=ax[1], kde=True, legend=False) ax[1].set_title(\"Scaled data\") plt.show() Scaling Example\nFurthermore, for normalization it represents a more radical transformation. We perform normalization because our observations cannot be described as a normal distribution. Normally, we perform normalization when the data will be used for machine learning or statistical technique that assumes the data is normally distributed.\n# normalize the exponential data with boxcox normalized_data = stats.boxcox(original_data) # plot both together to compare fig, ax=plt.subplots(1, 2, figsize=(15, 3)) sns.histplot(original_data, ax=ax[0], kde=True, legend=False) ax[0].set_title(\"Original Data\") sns.histplot(normalized_data[0], ax=ax[1], kde=True, legend=False) ax[1].set_title(\"Normalized data\") plt.show() Scaling Example\n3. Parsing Date Importing library:\n# modules we'll use import pandas as pd import numpy as np import seaborn as sns import datetime Let’s output the data column from the DataFrame to see if it really contains date:\n# print the first few rows of the date column print(landslides['date'].head()) 0 3/2/07 1 3/22/07 2 4/6/07 3 4/14/07 4 4/15/07 Name: date, dtype: object By observation, these outputs look like date. But the data type is being set to object. That means this date column is not being recognized as a date, and we need to convert it so that it can be recognized as date.\nlandslide['data_parsed'] = pd.to_datetime(landslide['date'], format = \"%m/%d/%y\") If we check back again:\n# print the first few rows landslides['date_parsed'].head() 0 2007-03-02 1 2007-03-22 2 2007-04-06 3 2007-04-14 4 2007-04-15 Name: date_parsed, dtype: datetime64[ns] We can see that now the date is being correctly recognized. Here’s some tip, if we run into an error with multiple date formats, we could run: landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True).\n3,.1 Select The Day of The Month dom = landslide['date_parsed'].dt.day dom.head() One of the biggest dangers in parsing dates is mixing up the months and days. The to_datetime() function does have very helpful error messages, but it doesn’t hurt to double-check that the days of the month we’ve extracted make sense.\n# remove na's day_of_month_landslides = day_of_month_landslides.dropna() # plot the day of the month sns.distplot(day_of_month_landslides, kde=False, bins=31) Scaling Example\nLooks like the date is parsed correctly.\n4. Character Encoding Import libraries:\n# modules we'll use import pandas as pd import numpy as np # helpful character encoding module import charset_normalizer # set seed for reproducibility np.random.seed(0) Character encoding are specific sets of rules for mapping from raw binary byte strings to character that make-up human-readable text. If you tried to read in text with a different encoding than the one it was originally written in, you ended up with scrambled text called mojibake (said like mo-gee-bah-kay). Here’s an example of mojibake:\næ–‡å—åŒ–ã?? In fact, character encoding mismatches are less common today. There are a lot of different character encoding out there, the main one for you to know is UTF-8.\nUTF-8 is the standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. It’s when things aren’t in UTF-8 that you run into trouble.\n# start with a string before = \"This is the euro symbol: €\" # check to see what datatype it is type(before) # output # str # encode it to a different encoding, replacing characters that raise errors after = before.encode(\"utf-8\", errors=\"replace\") # check the type type(after) # output # bytes # take a look at what the bytes look like after # output # b'This is the euro symbol: \\xe2\\x82\\xac' # convert it back to utf-8 print(after.decode(\"utf-8\")) # output # This is the euro symbol: € However, when we try to use a different encoding to map our bytes into a string, we get an error. This is because the encoding we’re trying to use doesn’t know what to do with the bytes we’re trying to pass it. You need to tell Python the encoding that the byte string is actually supposed to be in.\n5. Inconsistent Data Entry Import libraries:\n# modules we'll use import pandas as pd import numpy as np # helpful modules import fuzzywuzzy from fuzzywuzzy import process import charset_normalizer In this section, we would like to check the ‘country’ column to make sure that there is no data entry inconsistencies in it.\n# get all the unique values in the 'Country' column countries = professors['Country'].unique() # sort them alphabetically and then take a closer look countries.sort() countries array([' Germany', ' New Zealand', ' Sweden', ' USA', 'Australia', 'Austria', 'Canada', 'China', 'Finland', 'France', 'Greece', 'HongKong', 'Ireland', 'Italy', 'Japan', 'Macau', 'Malaysia', 'Mauritius', 'Netherland', 'New Zealand', 'Norway', 'Pakistan', 'Portugal', 'Russian Federation', 'Saudi Arabia', 'Scotland', 'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden', 'Thailand', 'Turkey', 'UK', 'USA', 'USofA', 'Urbana', 'germany'], dtype=object) We notice that there are some problems with this array of data. For instance, ‘germany’ and ‘Germany’; ‘New Zealand’ and ’ New Zealand’. Firstly, we would convert everything to the lower case and remove the white spaces at the beginning and the end:\ndf['Country'] = df['Country'].str.lower() df['Country'] = df['Country'].str.strip() Next, we want to perform fuzzy matching to correct inconsistent data entry.\n# get all the unique values in the 'Country' column countries = professors['Country'].unique() # sort them alphabetically and then take a closer look countries.sort() countries array(['australia', 'austria', 'canada', 'china', 'finland', 'france', 'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan', 'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand', 'norway', 'pakistan', 'portugal', 'russian federation', 'saudi arabia', 'scotland', 'singapore', 'south korea', 'southkorea', 'spain', 'sweden', 'thailand', 'turkey', 'uk', 'urbana', 'usa', 'usofa'], dtype=object) So what is it about fuzzy matching? Fuzzy matching is the process of automatically finding text strings that are very similar to the target string. In general, a string is considered “closer” to another one the fewer characters you’d need to change if you were transforming one string into another. So “apple” and “snapple” are two changes away from each other (add “s” and “n”) while “in” and “on” and one change away (replace “i” with “o”). You won’t always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\nFuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we’re going to get the ten strings from our list of cities that have the closest distance to “south korea”.\n# get the top 10 closest matches to \"south korea\" matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # take a look at them matches [('south korea', 100), ('southkorea', 48), ('saudi arabia', 43), ('norway', 35), ('austria', 33), ('ireland', 33), ('pakistan', 32), ('portugal', 32), ('scotland', 32), ('australia', 30)] We can see that the first two items appear to be similar. Let’s replace all rows in the ‘Country’ column that have a ratio \u003e 47 with “south korea”.\n# function to replace rows in the provided column of the provided dataframe # that match the provided string above the provided ratio with the provided string def replace_matches_in_column(df, column, string_to_match, min_ratio = 47): # get a list of unique strings strings = df[column].unique() # get the top 10 closest matches to our input string matches = fuzzywuzzy.process.extract(string_to_match, strings, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # only get matches with a ratio \u003e 90 close_matches = [matches[0] for matches in matches if matches[1] \u003e= min_ratio] # get the rows of all the close matches in our dataframe rows_with_matches = df[column].isin(close_matches) # replace all rows with close matches with the input matches df.loc[rows_with_matches, column] = string_to_match # let us know the function's done print(\"All done!\") # use the function we just wrote to replace close matches to \"south korea\" with \"south korea\" replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\") Now, let’s do a double check:\n# get all the unique values in the 'Country' column countries = professors['Country'].unique() # sort them alphabetically and then take a closer look countries.sort() countries array(['australia', 'austria', 'canada', 'china', 'finland', 'france', 'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan', 'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand', 'norway', 'pakistan', 'portugal', 'russian federation', 'saudi arabia', 'scotland', 'singapore', 'south korea', 'spain', 'sweden', 'thailand', 'turkey', 'uk', 'urbana', 'usa', 'usofa'], dtype=object) Now we can see that we only have “south korea” in the DataFrame!\n",
  "wordCount" : "2104",
  "inLanguage": "en",
  "datePublished": "2023-08-19T00:00:00Z",
  "dateModified": "2023-08-19T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Kean Teng Blog"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://keanteng.github.io/home/docs/2023-08-19-data-cleaning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kean Teng Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://i.postimg.cc/0Qq5g2fX/favicon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://keanteng.github.io/home/" accesskey="h" title="Kean Teng Blog (Alt + H)">Kean Teng Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://keanteng.github.io/home/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://keanteng.github.io/home/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://keanteng.github.io/home/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://keanteng.github.io/home/faqs/" title="FAQs">
                    <span>FAQs</span>
                </a>
            </li>
            <li>
                <a href="https://my.linkedin.com/in/khorkeanteng" title="LinkedIn">
                    <span>LinkedIn</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://keanteng.github.io/home/">Home</a>&nbsp;»&nbsp;<a href="https://keanteng.github.io/home/docs/">Docs</a></div>
    <h1 class="post-title">
      Data Cleaning
    </h1>
    <div class="post-description">
      My Kaggle Learning Note 
    </div>
    <div class="post-meta"><span title='2023-08-19 00:00:00 +0000 UTC'>August 19, 2023</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Kean Teng Blog

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-handling-missing-values" aria-label="1. Handling Missing Values">1. Handling Missing Values</a></li>
                <li>
                    <a href="#2-scaling--normalization" aria-label="2. Scaling &amp;amp; Normalization">2. Scaling &amp; Normalization</a></li>
                <li>
                    <a href="#3-parsing-date" aria-label="3. Parsing Date">3. Parsing Date</a><ul>
                        
                <li>
                    <a href="#31-select-the-day-of-the-month" aria-label="3,.1 Select The Day of The Month">3,.1 Select The Day of The Month</a></li></ul>
                </li>
                <li>
                    <a href="#4-character-encoding" aria-label="4. Character Encoding">4. Character Encoding</a></li>
                <li>
                    <a href="#5-inconsistent-data-entry" aria-label="5. Inconsistent Data Entry">5. Inconsistent Data Entry</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><center><img src="https://images.unsplash.com/photo-1493953659556-556b14bdaca8?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1333&q=800"  class = "center"/></center>
<p style="text-align: center; color:grey;"><i>Images from Unsplash</i></p>
<blockquote>
<p><em>Disclaimer: This article is my learning note from the courses I took from Kaggle.</em></p>
</blockquote>
<p>Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. It is a key part of data science, and it can be deeply frustrating. What should we do to the missing values? Why the dates are not in the correct format? How to clean up inconsistent data entry? These are some of the problems that we will learn to tackle in this course.</p>
<h2 id="1-handling-missing-values">1. Handling Missing Values<a hidden class="anchor" aria-hidden="true" href="#1-handling-missing-values">#</a></h2>
<p>Let&rsquo;s start by taking a look at the data and check how many missing values are there:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">missing</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">missing</span><span class="p">)</span>
</span></span></code></pre></div><p>Now let&rsquo;s look at the percentage of values in our dataset that were missing:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">total_cells</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">total_missing</span> <span class="o">=</span> <span class="n">missing</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">percent_missing</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_missing</span><span class="o">/</span><span class="n">total_cells</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">percent_missing</span><span class="p">)</span>
</span></span></code></pre></div><p>The next step is to figure out why the data is missing. It is important to ask ourselves, is this value missing because it wasn&rsquo;t recorded, or it doesn&rsquo;t exist? If it is the latter, it wouldn&rsquo;t make sense to guess those values, we could just leave them empty. But if it is the other way round, we probably would need to guess what it might have been based on some other values in the column and row.</p>
<p>We called this method as imputation. In statistics, imputation is the process of replacing missing data with substituted values.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># look at the # of missing points in the first ten columns</span>
</span></span><span class="line"><span class="cl"><span class="n">missing_values_count</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Date</span>                <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">GameID</span>              <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">Drive</span>               <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">qtr</span>                 <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">down</span>            <span class="mi">61154</span>
</span></span><span class="line"><span class="cl"><span class="n">time</span>              <span class="mi">224</span>
</span></span><span class="line"><span class="cl"><span class="n">TimeUnder</span>           <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">TimeSecs</span>          <span class="mi">224</span>
</span></span><span class="line"><span class="cl"><span class="n">PlayTimeDiff</span>      <span class="mi">444</span>
</span></span><span class="line"><span class="cl"><span class="n">SideofField</span>       <span class="mi">528</span>
</span></span><span class="line"><span class="cl"><span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</span></span></code></pre></div><p>We can see that the columns has information on the number of seconds left in the game when the play was made. These values are probably missing because they were not recorded, it would be better for us to try and have a guess on it.</p>
<p>Conversely, other fields such as <code>PenalizedTeam</code> contains a lot of missing fields. This is because if there was no penalty, then the field will be missed. We could just leave it empty as it is.</p>
<p>Of course, if we wouldn&rsquo;t want to guess for the missing value, we can remove the rows of columns with missing values:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span> <span class="c1"># remove rows with missing value</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># remove all columns with at least one missing value</span>
</span></span></code></pre></div><p>On the other hand, if we would like to try to fill in the missing value, we can use the Pandas&rsquo; <code>fillna</code> function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># get a small subset of the NFL dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">subset_nfl_data</span> <span class="o">=</span> <span class="n">nfl_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;EPA&#39;</span><span class="p">:</span><span class="s1">&#39;Season&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">subset_nfl_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># replace all NA&#39;s with 0</span>
</span></span><span class="line"><span class="cl"><span class="n">subset_nfl_data</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></div><p>If we want to replace the missing value with value comes directly after it in the same column:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># replace all NA&#39;s the value that comes directly after it in the same column, </span>
</span></span><span class="line"><span class="cl"><span class="c1"># then replace all the remaining na&#39;s with 0</span>
</span></span><span class="line"><span class="cl"><span class="n">subset_nfl_data</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;bfill&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="2-scaling--normalization">2. Scaling &amp; Normalization<a hidden class="anchor" aria-hidden="true" href="#2-scaling--normalization">#</a></h2>
<p>Let&rsquo;s start by importing some libraries:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># modules we&#39;ll use</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># for Box-Cox Transformation</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># for min_max scaling</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlxtend.preprocessing</span> <span class="kn">import</span> <span class="n">minmax_scaling</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plotting modules</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span></code></pre></div><p>The difference between scaling and normalization:</p>
<ul>
<li>Scaling: changing the range of data</li>
<li>Normalization: changing the shape of the distribution of the data</li>
</ul>
<p>When we perform scaling, we are transforming the data so that it fits within a specific scale like 0 to 1 or 1 to 100. We will scale data if we are using methods based on measures of how far apart data points are such as SVM (support vector machines) and KNN (k-nearest neighbors).</p>
<p>For example, you might be looking at the prices of some products in both Yen and US Dollars. One US Dollar is worth about 100 Yen, but if you don&rsquo;t scale your prices, methods like SVM or KNN will consider a difference in price of 1 Yen as important as a difference of 1 US Dollar! This clearly doesn&rsquo;t fit with our intuitions of the world. With currency, you can convert between currencies. But what about if you&rsquo;re looking at something like height and weight? It&rsquo;s not entirely clear how many pounds should equal one inch (or how many kilograms should equal one meter).</p>
<p>Scaling variables help us to compare different variables on equal footing. The shape of the data will not change with scaling, but the range will change.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># generate 1000 data points randomly drawn from an exponential distribution</span>
</span></span><span class="line"><span class="cl"><span class="n">original_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># mix-max scale the data between 0 and 1</span>
</span></span><span class="line"><span class="cl"><span class="n">scaled_data</span> <span class="o">=</span> <span class="n">minmax_scaling</span><span class="p">(</span><span class="n">original_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot both together to compare</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">original_data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&#34;Original Data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&#34;Scaled data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><center><img src="images/minmax.png"  class = "center"/></center>
<p style="text-align: center; color:grey;"><i>Scaling Example</i></p>
<p>Furthermore, for normalization it represents a more radical transformation. We perform normalization because our observations cannot be described as a normal distribution. Normally, we perform normalization when the data will be used for machine learning or statistical technique that assumes the data is normally distributed.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># normalize the exponential data with boxcox</span>
</span></span><span class="line"><span class="cl"><span class="n">normalized_data</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">boxcox</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot both together to compare</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">original_data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&#34;Original Data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">normalized_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&#34;Normalized data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><center><img src="images/norm.png"  class = "center"/></center>
<p style="text-align: center; color:grey;"><i>Scaling Example</i></p>
<h2 id="3-parsing-date">3. Parsing Date<a hidden class="anchor" aria-hidden="true" href="#3-parsing-date">#</a></h2>
<p>Importing library:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># modules we&#39;ll use</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">datetime</span>
</span></span></code></pre></div><p>Let&rsquo;s output the data column from the <code>DataFrame</code> to see if it really contains date:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt"><span class="line"><span class="cl"># print the first few rows of the date column
</span></span><span class="line"><span class="cl">print(landslides[&#39;date&#39;].head())
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">0     3/2/07
</span></span><span class="line"><span class="cl">1    3/22/07
</span></span><span class="line"><span class="cl">2     4/6/07
</span></span><span class="line"><span class="cl">3    4/14/07
</span></span><span class="line"><span class="cl">4    4/15/07
</span></span><span class="line"><span class="cl">Name: date, dtype: object
</span></span></code></pre></div><p>By observation, these outputs look like date. But the data type is being set to object. That means this date column is not being recognized as a date, and we need to convert it so that it can be recognized as date.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">landslide</span><span class="p">[</span><span class="s1">&#39;data_parsed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">landslide</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="nb">format</span> <span class="o">=</span> <span class="s2">&#34;%m/</span><span class="si">%d</span><span class="s2">/%y&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>If we check back again:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt"><span class="line"><span class="cl"># print the first few rows
</span></span><span class="line"><span class="cl">landslides[&#39;date_parsed&#39;].head()
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">0   2007-03-02
</span></span><span class="line"><span class="cl">1   2007-03-22
</span></span><span class="line"><span class="cl">2   2007-04-06
</span></span><span class="line"><span class="cl">3   2007-04-14
</span></span><span class="line"><span class="cl">4   2007-04-15
</span></span><span class="line"><span class="cl">Name: date_parsed, dtype: datetime64[ns]
</span></span></code></pre></div><p>We can see that now the date is being correctly recognized. Here&rsquo;s some tip, if we run into an error with multiple date formats, we could run: <code>landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)</code>.</p>
<h3 id="31-select-the-day-of-the-month">3,.1 Select The Day of The Month<a hidden class="anchor" aria-hidden="true" href="#31-select-the-day-of-the-month">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">dom</span> <span class="o">=</span> <span class="n">landslide</span><span class="p">[</span><span class="s1">&#39;date_parsed&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">day</span>
</span></span><span class="line"><span class="cl"><span class="n">dom</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span></code></pre></div><p>One of the biggest dangers in parsing dates is mixing up the months and days. The <code>to_datetime()</code> function does have very helpful error messages, but it doesn&rsquo;t hurt to double-check that the days of the month we&rsquo;ve extracted make sense.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># remove na&#39;s</span>
</span></span><span class="line"><span class="cl"><span class="n">day_of_month_landslides</span> <span class="o">=</span> <span class="n">day_of_month_landslides</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot the day of the month</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">day_of_month_landslides</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>
</span></span></code></pre></div><center><img src="images/DOM.png"  class = "center"/></center>
<p style="text-align: center; color:grey;"><i>Scaling Example</i></p>
<p>Looks like the date is parsed correctly.</p>
<h2 id="4-character-encoding">4. Character Encoding<a hidden class="anchor" aria-hidden="true" href="#4-character-encoding">#</a></h2>
<p>Import libraries:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># modules we&#39;ll use</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># helpful character encoding module</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">charset_normalizer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># set seed for reproducibility</span>
</span></span><span class="line"><span class="cl"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></div><p>Character encoding are specific sets of rules for mapping from raw binary byte strings to character that make-up human-readable text. If you tried to read in text with a different encoding than the one it was originally written in, you ended up with scrambled text called <code>mojibake</code> (said like <code>mo-gee-bah-kay</code>). Here&rsquo;s an example of <code>mojibake</code>:</p>
<pre tabindex="0"><code>æ–‡å—åŒ–ã??
</code></pre><p>In fact, character encoding mismatches are less common today. There are a lot of different character encoding out there, the main one for you to know is UTF-8.</p>
<p>UTF-8 is the standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. It&rsquo;s when things aren&rsquo;t in UTF-8 that you run into trouble.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># start with a string</span>
</span></span><span class="line"><span class="cl"><span class="n">before</span> <span class="o">=</span> <span class="s2">&#34;This is the euro symbol: €&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># check to see what datatype it is</span>
</span></span><span class="line"><span class="cl"><span class="nb">type</span><span class="p">(</span><span class="n">before</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># output</span>
</span></span><span class="line"><span class="cl"><span class="c1"># str</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># encode it to a different encoding, replacing characters that raise errors</span>
</span></span><span class="line"><span class="cl"><span class="n">after</span> <span class="o">=</span> <span class="n">before</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&#34;utf-8&#34;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&#34;replace&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># check the type</span>
</span></span><span class="line"><span class="cl"><span class="nb">type</span><span class="p">(</span><span class="n">after</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># output</span>
</span></span><span class="line"><span class="cl"><span class="c1"># bytes</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># take a look at what the bytes look like</span>
</span></span><span class="line"><span class="cl"><span class="n">after</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># output</span>
</span></span><span class="line"><span class="cl"><span class="c1"># b&#39;This is the euro symbol: \xe2\x82\xac&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># convert it back to utf-8</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">after</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&#34;utf-8&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># output</span>
</span></span><span class="line"><span class="cl"><span class="c1"># This is the euro symbol: €</span>
</span></span></code></pre></div><p>However, when we try to use a different encoding to map our bytes into a string, we get an error. This is because the encoding we&rsquo;re trying to use doesn&rsquo;t know what to do with the bytes we&rsquo;re trying to pass it. You need to tell Python the encoding that the byte string is actually supposed to be in.</p>
<h2 id="5-inconsistent-data-entry">5. Inconsistent Data Entry<a hidden class="anchor" aria-hidden="true" href="#5-inconsistent-data-entry">#</a></h2>
<p>Import libraries:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># modules we&#39;ll use</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># helpful modules</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">fuzzywuzzy</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">fuzzywuzzy</span> <span class="kn">import</span> <span class="n">process</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">charset_normalizer</span>
</span></span></code></pre></div><p>In this section, we would like to check the &lsquo;country&rsquo; column to make sure that there is no data entry inconsistencies in it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># get all the unique values in the &#39;Country&#39; column</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span> <span class="o">=</span> <span class="n">professors</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># sort them alphabetically and then take a closer look</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span>
</span></span></code></pre></div><pre tabindex="0"><code>array([&#39; Germany&#39;, &#39; New Zealand&#39;, &#39; Sweden&#39;, &#39; USA&#39;, &#39;Australia&#39;,
       &#39;Austria&#39;, &#39;Canada&#39;, &#39;China&#39;, &#39;Finland&#39;, &#39;France&#39;, &#39;Greece&#39;,
       &#39;HongKong&#39;, &#39;Ireland&#39;, &#39;Italy&#39;, &#39;Japan&#39;, &#39;Macau&#39;, &#39;Malaysia&#39;,
       &#39;Mauritius&#39;, &#39;Netherland&#39;, &#39;New Zealand&#39;, &#39;Norway&#39;, &#39;Pakistan&#39;,
       &#39;Portugal&#39;, &#39;Russian Federation&#39;, &#39;Saudi Arabia&#39;, &#39;Scotland&#39;,
       &#39;Singapore&#39;, &#39;South Korea&#39;, &#39;SouthKorea&#39;, &#39;Spain&#39;, &#39;Sweden&#39;,
       &#39;Thailand&#39;, &#39;Turkey&#39;, &#39;UK&#39;, &#39;USA&#39;, &#39;USofA&#39;, &#39;Urbana&#39;, &#39;germany&#39;],
      dtype=object)
</code></pre><p>We notice that there are some problems with this array of data. For instance, &lsquo;germany&rsquo; and &lsquo;Germany&rsquo;; &lsquo;New Zealand&rsquo; and &rsquo; New Zealand&rsquo;. Firstly, we would convert everything to the lower case and remove the white spaces at the beginning and the end:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span></span></code></pre></div><p>Next, we want to perform fuzzy matching to correct inconsistent data entry.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># get all the unique values in the &#39;Country&#39; column</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span> <span class="o">=</span> <span class="n">professors</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># sort them alphabetically and then take a closer look</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span>
</span></span></code></pre></div><pre tabindex="0"><code>array([&#39;australia&#39;, &#39;austria&#39;, &#39;canada&#39;, &#39;china&#39;, &#39;finland&#39;, &#39;france&#39;,
       &#39;germany&#39;, &#39;greece&#39;, &#39;hongkong&#39;, &#39;ireland&#39;, &#39;italy&#39;, &#39;japan&#39;,
       &#39;macau&#39;, &#39;malaysia&#39;, &#39;mauritius&#39;, &#39;netherland&#39;, &#39;new zealand&#39;,
       &#39;norway&#39;, &#39;pakistan&#39;, &#39;portugal&#39;, &#39;russian federation&#39;,
       &#39;saudi arabia&#39;, &#39;scotland&#39;, &#39;singapore&#39;, &#39;south korea&#39;,
       &#39;southkorea&#39;, &#39;spain&#39;, &#39;sweden&#39;, &#39;thailand&#39;, &#39;turkey&#39;, &#39;uk&#39;,
       &#39;urbana&#39;, &#39;usa&#39;, &#39;usofa&#39;], dtype=object)
</code></pre><p>So what is it about fuzzy matching? Fuzzy matching is the process of automatically finding text strings that are very similar to the target string. In general, a string is considered &ldquo;closer&rdquo; to another one the fewer characters you&rsquo;d need to change if you were transforming one string into another. So &ldquo;apple&rdquo; and &ldquo;snapple&rdquo; are two changes away from each other (add &ldquo;s&rdquo; and &ldquo;n&rdquo;) while &ldquo;in&rdquo; and &ldquo;on&rdquo; and one change away (replace &ldquo;i&rdquo; with &ldquo;o&rdquo;). You won&rsquo;t always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.</p>
<p>Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we&rsquo;re going to get the ten strings from our list of cities that have the closest distance to &ldquo;south korea&rdquo;.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># get the top 10 closest matches to &#34;south korea&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">matches</span> <span class="o">=</span> <span class="n">fuzzywuzzy</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="s2">&#34;south korea&#34;</span><span class="p">,</span> <span class="n">countries</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scorer</span><span class="o">=</span><span class="n">fuzzywuzzy</span><span class="o">.</span><span class="n">fuzz</span><span class="o">.</span><span class="n">token_sort_ratio</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># take a look at them</span>
</span></span><span class="line"><span class="cl"><span class="n">matches</span>
</span></span></code></pre></div><pre tabindex="0"><code>[(&#39;south korea&#39;, 100),
 (&#39;southkorea&#39;, 48),
 (&#39;saudi arabia&#39;, 43),
 (&#39;norway&#39;, 35),
 (&#39;austria&#39;, 33),
 (&#39;ireland&#39;, 33),
 (&#39;pakistan&#39;, 32),
 (&#39;portugal&#39;, 32),
 (&#39;scotland&#39;, 32),
 (&#39;australia&#39;, 30)]
</code></pre><p>We can see that the first two items appear to be similar. Let&rsquo;s replace all rows in the &lsquo;Country&rsquo; column that have a ratio &gt; 47 with &ldquo;south korea&rdquo;.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># function to replace rows in the provided column of the provided dataframe</span>
</span></span><span class="line"><span class="cl"><span class="c1"># that match the provided string above the provided ratio with the provided string</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">replace_matches_in_column</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">string_to_match</span><span class="p">,</span> <span class="n">min_ratio</span> <span class="o">=</span> <span class="mi">47</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># get a list of unique strings</span>
</span></span><span class="line"><span class="cl">    <span class="n">strings</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># get the top 10 closest matches to our input string</span>
</span></span><span class="line"><span class="cl">    <span class="n">matches</span> <span class="o">=</span> <span class="n">fuzzywuzzy</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">string_to_match</span><span class="p">,</span> <span class="n">strings</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                         <span class="n">limit</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scorer</span><span class="o">=</span><span class="n">fuzzywuzzy</span><span class="o">.</span><span class="n">fuzz</span><span class="o">.</span><span class="n">token_sort_ratio</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># only get matches with a ratio &gt; 90</span>
</span></span><span class="line"><span class="cl">    <span class="n">close_matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">matches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">matches</span> <span class="ow">in</span> <span class="n">matches</span> <span class="k">if</span> <span class="n">matches</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_ratio</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># get the rows of all the close matches in our dataframe</span>
</span></span><span class="line"><span class="cl">    <span class="n">rows_with_matches</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">close_matches</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># replace all rows with close matches with the input matches </span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">rows_with_matches</span><span class="p">,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">string_to_match</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># let us know the function&#39;s done</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;All done!&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># use the function we just wrote to replace close matches to &#34;south korea&#34; with &#34;south korea&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">replace_matches_in_column</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">professors</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="s1">&#39;Country&#39;</span><span class="p">,</span> <span class="n">string_to_match</span><span class="o">=</span><span class="s2">&#34;south korea&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>Now, let&rsquo;s do a double check:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># get all the unique values in the &#39;Country&#39; column</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span> <span class="o">=</span> <span class="n">professors</span><span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># sort them alphabetically and then take a closer look</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">countries</span>
</span></span></code></pre></div><pre tabindex="0"><code>array([&#39;australia&#39;, &#39;austria&#39;, &#39;canada&#39;, &#39;china&#39;, &#39;finland&#39;, &#39;france&#39;,
       &#39;germany&#39;, &#39;greece&#39;, &#39;hongkong&#39;, &#39;ireland&#39;, &#39;italy&#39;, &#39;japan&#39;,
       &#39;macau&#39;, &#39;malaysia&#39;, &#39;mauritius&#39;, &#39;netherland&#39;, &#39;new zealand&#39;,
       &#39;norway&#39;, &#39;pakistan&#39;, &#39;portugal&#39;, &#39;russian federation&#39;,
       &#39;saudi arabia&#39;, &#39;scotland&#39;, &#39;singapore&#39;, &#39;south korea&#39;, &#39;spain&#39;,
       &#39;sweden&#39;, &#39;thailand&#39;, &#39;turkey&#39;, &#39;uk&#39;, &#39;urbana&#39;, &#39;usa&#39;, &#39;usofa&#39;],
      dtype=object)
</code></pre><p>Now we can see that we only have &ldquo;south korea&rdquo; in the <code>DataFrame</code>!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://keanteng.github.io/home/tags/pandas/">Pandas</a></li>
      <li><a href="https://keanteng.github.io/home/tags/data-frame/">Data Frame</a></li>
      <li><a href="https://keanteng.github.io/home/tags/data-cleaning/">Data Cleaning</a></li>
      <li><a href="https://keanteng.github.io/home/tags/data-manipulation/">Data Manipulation</a></li>
      <li><a href="https://keanteng.github.io/home/tags/python/">Python</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://keanteng.github.io/home/docs/2023-08-20-feature-engineering/">
    <span class="title">« Prev</span>
    <br>
    <span>Feature Engineering</span>
  </a>
  <a class="next" href="https://keanteng.github.io/home/docs/2023-08-19-time-series/">
    <span class="title">Next »</span>
    <br>
    <span>Time Series</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on twitter"
        href="https://twitter.com/intent/tweet/?text=Data%20Cleaning&amp;url=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f&amp;hashtags=Pandas%2cDataFrame%2cDataCleaning%2cDataManipulation%2cPython">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f&amp;title=Data%20Cleaning&amp;summary=Data%20Cleaning&amp;source=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f&title=Data%20Cleaning">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on whatsapp"
        href="https://api.whatsapp.com/send?text=Data%20Cleaning%20-%20https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Data Cleaning on telegram"
        href="https://telegram.me/share/url?text=Data%20Cleaning&amp;url=https%3a%2f%2fkeanteng.github.io%2fhome%2fdocs%2f2023-08-19-data-cleaning%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://keanteng.github.io/home/">Kean Teng Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
